I"E
<div id="sina_keyword_ad_area2" class="articalContent   ">
  <div style="">
    这几天在做一个对内的服务：&lt;/p&gt; 
    
    <p>
      由一个封装好的类发送curl请求到接收端，接收端收到鉴权后入到队列内。
    </p>
    
    <p>
      开发完毕后自己使用php单进程能够达到每秒400左右请求。
    </p>
    
    <p>
      但是使用ab、loadrunner，100高并发的时候发现每秒只能处理8个请求。
    </p>
    
    <p>
      而并发在10个的时候一切正常
    </p>
    
    <p>
      经过测试发现当发送端和接收端都在同一台服务器的时候会有这个现象。
    </p>
    
    <p>
      起初怀疑是curl有问题，几次尝试无果。
    </p>
    
    <p>
      又通过写性能日志进行排查，发现php客户端处curl执行时间很长（平均8秒处理完一个），响应端代码实际处理时间很短。
    </p>
    
    <p>
      而用top命令发现php-fpm进程启动很少，只有10几个每秒
    </p>
    
    <p>
      百思不得其解……
    </p>
    
    <p>
      后来单步调试逐步将注意力从curl上转到nginx及php-fpm上，首先觉得nginx肯定没问题，后来转移到php-fpm上，发现curl请求虽然过去，但是php-fpm好像被限制住，启动很多链接接口但是就是不处理一直在等待。
    </p>
    
    <p>
      查看linux load正常
    </p>
    
    <p>
      中午吃饭前四处搜索了下优化相关信息
    </p>
    
    <p>
      突然发现linux下最大文件打开数的提示
    </p>
    
    <p>
      悲催啊，终于找到原因在哪里了
    </p>
    
    <p>
      php-fpm自己限制了进程可以打开文件个数，linux下也对最大打开文件个数进行了限制
    </p>
    
    <p>
      我们的开发机是虚拟机，所以也没有针对运营时使用环境进行优化……
    </p>
    
    <p>
      解决方法如下<br /><b>修改php-fpm.conf</b><br />rlimit_files改成65535
    </p>
    
    <p>
      <b>修改/etc/security/limits.conf</b><br />* soft nofile 51200<br />* hard nofile 51200
    </p>
    
    <p>
      用命令netstat -np | grep:9000 |wc -l如果很少<br />那么修改php-fpm.conf<br />max_children改多一些比如200
    </p>
    
    <p>
      手动执行以下命令可以增加系统打开文件句柄个数<br />ulimit -HSn 65536
    </p>
    
    <p>
      ulimit -n可以查看当前最大打开文件句柄个数
    </p>
    
    <p>
      以上……经过测试，每秒8个请求的事情解决掉了，各种黑线……
    </p>
  </div>
</div>
:ET